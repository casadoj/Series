{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "Crea las series diarias de temperatura máxima, mínima y media de las estaciones de la AEMET en toda España en el periodo 1950-2015.\n",
    "Los datos provienen de una serie de archivos en las que se dividen por zonas del país y periodos de varios años"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from mpl_toolkits.basemap import Basemap, cm\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import tqdm\n",
    "from dateutil import parser\n",
    "import datetime\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variable\n",
    "var = 'Pd'\n",
    "\n",
    "# Ruta de los datos y carpetas\n",
    "ruta_series = 'F:/Series/AEMET/2016_pet080_UNICAN/data/'\n",
    "folders = ['Ind_0001_3015', 'Ind_3018E_6250', 'Ind_6251_9812E', 'Ind_9813_C939U']\n",
    "ruta_exportar = 'F:/Series/AEMET/2016_pet080_UNICAN/data/Precipitacion/'\n",
    "\n",
    "# Define el periodo de estudio\n",
    "time = pd.date_range(start='1950-01-01', end='2015-12-31', freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraer las estaciones\n",
    "\n",
    "Se extraen las estaciones con alguna medición y sus características (código, nombre, coordenadas, altitud, provincia).\n",
    "\n",
    "__Lista de archivos__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de archivos: 61\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "for folder in folders:\n",
    "    # Genera la serie de rutas de los archivos\n",
    "    f = glob.glob(ruta_series + folder + '/Datos-' + var + '*')\n",
    "    f = np.sort(f)\n",
    "    files.append(f)\n",
    "    del f\n",
    "# Convertir la lista a una dimensión\n",
    "files = list(chain.from_iterable(files))\n",
    "\n",
    "print('Nº de archivos:', len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:43<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de estaciones: 3381\n"
     ]
    }
   ],
   "source": [
    "# Extraer características de las estaciones\n",
    "estaciones = pd.DataFrame(columns=['INDICATIVO', 'NOMBRE', 'ALTITUD', 'C_X', 'C_Y', 'NOM_PROV', 'LONGITUD', 'LATITUD'])\n",
    "estaciones.set_index('INDICATIVO', drop=True, inplace=True)\n",
    "\n",
    "# Buscar estaciones y sus características en todos los archivos\n",
    "for file in tqdm.tqdm(files):\n",
    "    aux = pd.read_csv(file, sep=';', encoding='latin-1', usecols=[0, 4, 5, 6, 7, 8, 9 , 10], index_col=0,\n",
    "                      dtype={'INDICATIVO': str, 'NOM_PROV': str, 'LONGITUD': str})\n",
    "    for stn in aux.index.unique():\n",
    "        if stn not in estaciones.index:\n",
    "            estaciones = pd.concat((estaciones, pd.DataFrame(aux.loc[stn,:].iloc[0]).T), axis=0, join='outer')\n",
    "            \n",
    "# Exportar las características de las estaciones\n",
    "estaciones.index.name = 'INDICATIVO'\n",
    "estaciones.to_csv(ruta_exportar + 'Estaciones.csv')\n",
    "\n",
    "print('Nº de estaciones:', estaciones.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar las series diarias\n",
    "\n",
    "Se importan los datos del conjunto de archivos antes definidos, se concatenan las distintas series temporales de cada estación y se unen todas las estaciones en un mismo \"data frame\" para cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Crea los \"data frame\" con los nombre de la carpeta en el que se guardarán todas las series, siendo las files la\n",
    "# fecha y las columnas las estaciones\n",
    "Pd = pd.DataFrame(index=time, columns=estaciones.index)\n",
    "Pd.index.name = 'FECHA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▋                                                                                | 2/61 [01:48<53:12, 54.11s/it]"
     ]
    }
   ],
   "source": [
    "# Completa el data frame\n",
    "for file in tqdm.tqdm(files):\n",
    "    aux = pd.read_csv(file, sep=';', encoding='latin-1', dtype={'INDICATIVO': str, 'NOM_PROV': str, 'LONGITUD': str})\n",
    "    ids = []\n",
    "    ids_t = []\n",
    "    for xx, x in enumerate(aux.INDICATIVO):\n",
    "        if isinstance(x, float): # si 'x' es real, convierte en entero\n",
    "            x = int(x); \n",
    "        if isinstance(x, int): # si 'x' es un entero, convierte en caracteres\n",
    "            x = str(x);  \n",
    "        ids_t.append(x)\n",
    "        if x not in ids:\n",
    "            ids.append(x) #no los guardo si ya están repetidos\n",
    "    aux.INDICATIVO = ids_t    \n",
    "\n",
    "    for x in ids: # para cada estación\n",
    "        # Genera un \"data frame\" con sólo las filas de la estación en cuestión\n",
    "        aux_cut = aux.copy()\n",
    "        aux_cut = aux_cut.loc[np.where(aux_cut.INDICATIVO == x)[0]]\n",
    "        # Crea una serie de fechas en las que la estación tiene datos\n",
    "        time_aux = [datetime.datetime(aux_cut.AÑO.values[t], aux_cut.MES.values[t], aux_cut.DIA.values[t]) \n",
    "                    for t in range(len(aux_cut.AÑO))]\n",
    "        # Crea el \"data frame\" con tantas filas como fechas hay dato para la estación\n",
    "        dataframe_aux = pd.DataFrame(index=time_aux, columns=['P77'])\n",
    "        # Completar la serie con los datos\n",
    "        dataframe_aux.P77 = aux_cut.P77.values\n",
    "        # Asignar los datos a la matriz de la magnitud correspondiente\n",
    "        Pd[x].loc[dataframe_aux.index] = dataframe_aux.P77.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exporta las series completas de temperatura máxima, mínima y media dentro de la carpeta\n",
    "Pd.to_csv(ruta_exportar + 'Pd_1950.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Nº de estaciones:', len(Pd.columns.unique()))\n",
    "print('Nº de días:', Pd.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
