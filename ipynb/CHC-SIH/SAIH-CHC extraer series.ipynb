{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Autor:_    __Jesús Casado__ <br> _Revisión:_ __21/01/2019__ <br>\n",
    "\n",
    "\n",
    "__Descripción__:<br>\n",
    "Se extraen las series de las estaciones meteorológicas y de aforo necesarias para la simulación de la cuenca del río Nansa.\n",
    "\n",
    "\n",
    "__Cosas a corregir__ <br>\n",
    "\n",
    "\n",
    "__Índice__<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-dark')\n",
    "%matplotlib inline\n",
    "from simpledbf import Dbf5\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Estaciones de Cantabria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rutaSAIH = 'F:/Series/CHC/SAI/ESTACIONES CHC DE CANTABRIA/'\n",
    "rutaSAIH1 = 'F:/Series/CHC/SAI/ESTACIONES CHC DE CANTABRIA/Hasta junio de 2015/Cincominutales hasta junio de 2015/'\n",
    "rutaSAIH2 = 'F:/Series/CHC/SAI/ESTACIONES CHC DE CANTABRIA/Desde julio de 2015/Cincominutales desde julio de 2015/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SAIH_CHC_diario' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c9ede84f529f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSAIH_CHC_diario\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1252'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrutaSAIH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'SAIH_CHC_diario' is not defined"
     ]
    }
   ],
   "source": [
    "SAIH_CHC_diario('1252', rutaSAIH, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAIH_CHC_diario(estacion, ruta, verbose=True):\n",
    "    \"\"\"Genera las series diarias para las estaciones del SAIH Cantábrico.\n",
    "    \n",
    "    Entradas:\n",
    "    ---------\n",
    "    estacion: str o int. Nombre de la estación\n",
    "    ruta:     str\n",
    "    verbose:  boolean.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    \"\"\"\n",
    "    \n",
    "    # rutas\n",
    "    rutaSAIH1 = ruta + '/Hasta junio de 2015/'\n",
    "    rutaSAIH2 = ruta + '/Desde julio de 2015/'\n",
    "    \n",
    "    # PARTE 1\n",
    "    # -------\n",
    "    # encontrar archivos de la estación\n",
    "    folders = os.listdir(rutaSAIH1)\n",
    "    for f, folder in enumerate(folders):\n",
    "        if folder[-4:] == str(estacion):\n",
    "            ruta = rutaSAIH1 + folder + '/'\n",
    "            files = []\n",
    "            for file in os.listdir(ruta):\n",
    "                if file[:4] == folder[:4]:\n",
    "                    files.append(file)\n",
    "\n",
    "            # Importar datos cincominutales\n",
    "            data1 = pd.DataFrame()\n",
    "            uds = {}\n",
    "            for i, file in enumerate(files):\n",
    "                # importar serie original\n",
    "                aux = pd.read_csv(ruta + file, sep=';', encoding='latin-1', decimal=',', low_memory=False)\n",
    "                aux.dropna(axis=0, how='all', inplace=True)\n",
    "                aux.Fecha = [datetime.strptime(date, '%d/%m/%Y %H:%M') for date in aux.Fecha]\n",
    "                aux.set_index('Fecha', drop=True, inplace=True)\n",
    "                # reordenar 'aux' por señales\n",
    "                signals = aux['Nombre señal'].unique()\n",
    "                aux2 = pd.DataFrame()\n",
    "                for signal in signals:\n",
    "                    temp = aux.loc[aux['Nombre señal'] == signal, ['Valor', 'Unidades', 'Calidad']]\n",
    "                    uds[signal] = temp.Unidades[0]\n",
    "                    temp.columns = [signal, 'Unidades', 'Calidad']\n",
    "                    aux2 = pd.concat((aux2, temp[signal]), axis=1)\n",
    "                # concatenar a la serie generada\n",
    "                data1 = pd.concat((data1, aux2), axis=0)\n",
    "\n",
    "            # Agregar datos a diarios\n",
    "            data1_d = data1.groupby(by=[data1.index.year, data1.index.month, data1.index.day]).mean()\n",
    "            data1_d.index = [pd.datetime(y, m, d).date() for (y, m, d) in data1_d.index]\n",
    "\n",
    "            st, en = data1_d.index[0], data1_d.index[-1]\n",
    "            if data1_d.shape[0] != pd.date_range(st, en).shape[0]:\n",
    "                aux = data1_d.copy()\n",
    "                data1_d = pd.DataFrame(index=pd.date_range(st, en), columns=data1_d.columns)\n",
    "                for date in aux.index:\n",
    "                    data1_d.loc[date, :] = aux.loc[date, :]\n",
    "            del files\n",
    "            \n",
    "    # PARTE 2\n",
    "    # -------\n",
    "    # encontrar carpeta de la estación\n",
    "    folders = os.listdir(rutaSAIH2)\n",
    "    for folder in folders:\n",
    "        if folder[-4:] == str(estacion):\n",
    "            ruta = rutaSAIH2 + folder + '/'\n",
    "            # encontrar archivos de la estación\n",
    "            files = os.listdir(ruta)\n",
    "            \n",
    "            # Importar datos cincominutales\n",
    "            data2 = pd.DataFrame()\n",
    "            for file in files:\n",
    "                aux = pd.read_csv(ruta + file, sep=';', decimal=',', encoding='latin-1', skiprows=1)\n",
    "                aux['Fecha/Hora'] = [datetime.strptime(date, '%d/%m/%Y %H:%M') for date in aux['Fecha/Hora']]\n",
    "                aux.set_index('Fecha/Hora', drop=True, inplace=True)\n",
    "                aux.index.name = 'Fecha'\n",
    "                data2 = pd.concat((data2, aux), axis=0)\n",
    "\n",
    "            # Agregar datos a diarios\n",
    "            data2_d = data2.groupby(by=[data2.index.year, data2.index.month, data2.index.day]).mean()\n",
    "            data2_d.index = [pd.datetime(y, m, d).date() for (y, m, d) in data2_d.index]\n",
    "\n",
    "            st, en = data2_d.index[0], data2_d.index[-1]\n",
    "            if data2_d.shape[0] != pd.date_range(st, en).shape[0]:\n",
    "                print('¡ERROR EN PARTE 2! Menor número de filas que días entre la fecha inicial y final.')\n",
    "        \n",
    "    # UNIR SERIES\n",
    "    # -----------\n",
    "    # unir las dos series\n",
    "    if ('data1_d' in locals()) and ('data2_d' in locals()):\n",
    "        st1, en1 = data1_d.index[0], data1_d.index[-1]\n",
    "        st2, en2 = data2_d.index[0], data2_d.index[-1]\n",
    "        idx = pd.date_range(st1, en2)\n",
    "        data_d = pd.DataFrame(index=idx, columns=data1_d.columns)\n",
    "        data_d.loc[st2:en2,:] = data2_d\n",
    "        data_d.loc[st1:en1,:] = data1_d\n",
    "    elif ('data1_d' in locals()) and ('data2_d' not in locals()):\n",
    "        data_d = data1_d.copy()\n",
    "    elif ('data2_d' in locals()) and ('data1_d' not in locals()): \n",
    "        data_d = data2_d.copy()\n",
    "    # corregir columnas\n",
    "    cols = []\n",
    "    for col in data_d.columns:\n",
    "        if col[-8:] == 'XACQRIO1':\n",
    "            data_d[col] = [round(d, 1) for d in data_d[col]]\n",
    "            cols.append('caudal_m³/s')\n",
    "        elif col[-8:] == 'XAINRIO1':\n",
    "            data_d[col] = [round(d, 3) for d in data_d[col]]\n",
    "            cols.append('nivel_m')\n",
    "        elif col[-8:] == 'XAIPCINC':\n",
    "            data_d[col] = data_d[col] * 24 * 60 / 5 # precipitación diaria acumulada\n",
    "            data_d[col] = [round(d, 1) for d in data_d[col]]\n",
    "            cols.append('precipitacion_mm')\n",
    "        elif col[-8:] == 'XAITEMEX':\n",
    "            data_d[col] = [round(d, 1) for d in data_d[col]]\n",
    "            cols.append('temperatura_ºC')\n",
    "    data_d.columns = cols\n",
    "    data_d.index.name = 'Fecha'\n",
    "\n",
    "    # comprobar fechas\n",
    "    st, en = data_d.index[0], data_d.index[-1]\n",
    "    if data_d.shape[0] != pd.date_range(st, en).shape[0]:\n",
    "        print('¡ERROR AL UNIR SERIES! Distinto número de filas que días entre la fecha inicial y final.')\n",
    "    \n",
    "    # exportar\n",
    "    if not os.path.exists(rutaSAIH + '1d/'):\n",
    "            os.makedirs(rutaSAIH + '1d/')\n",
    "    data_d.to_csv(rutaSAIH + '1d/' + folder + '.csv', sep=',', na_rep=-100)\n",
    "    \n",
    "    if verbose == True:\n",
    "        print('nº de días de las serie:\\t', data_d.shape[0])\n",
    "        print('variables:\\t', list(data_d.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encontrar estaciones\n",
    "stns = [file[-4:] for file in os.listdir(rutaSAIH1)]\n",
    "for file in os.listdir(rutaSAIH2):\n",
    "    if file[-4:] not in stns:\n",
    "        stns.append(file[-4:])\n",
    "stns.sort()\n",
    "\n",
    "len(stns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, stn in enumerate(stns):\n",
    "    print('estación', str(stn), '\\tserie', i, 'de', len(stns))\n",
    "    SAIH_CHC_diario(stn, rutaSAIH)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estaciones fuera de Cantabria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rutaSAIH = 'F:/Series/CHC/SAI/0_IHCantabria_20180626/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Crear carpetas antes de 2015__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta1 = rutaSAIH + 'Hasta junio de 2015/'\n",
    "os.chdir(ruta)\n",
    "\n",
    "# encontrar archivos csv\n",
    "files = []\n",
    "for file in os.listdir():\n",
    "    if file[-3:] == 'csv':\n",
    "        files.append(file)\n",
    "\n",
    "# Crear carpeta de cada estación y mover archivos a la carpeta correspondiente\n",
    "stns1 = []\n",
    "for file in files:\n",
    "    stn = file[:4]\n",
    "    if stn not in stns1:\n",
    "        stns1.append(stn)\n",
    "        if not os.path.exists(stn):\n",
    "            os.makedirs(stn)\n",
    "    os.rename(ruta + file, ruta + '/' + stn + '/' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Crear carpetas desde 2015__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta2 = rutaSAIH + 'Desde julio de 2015/'\n",
    "os.chdir(ruta)\n",
    "\n",
    "# encontrar archivos csv\n",
    "files = []\n",
    "for file in os.listdir():\n",
    "    if file[-3:] == 'csv':\n",
    "        files.append(file)\n",
    "\n",
    "# Crear carpeta de cada estación y mover archivos a la carpeta correspondiente\n",
    "stns2 = []\n",
    "for file in files:\n",
    "    stn = file[8:12]\n",
    "    if stn not in stns2:\n",
    "        stns2.append(stn)\n",
    "        if not os.path.exists(stn):\n",
    "            os.makedirs(stn)\n",
    "    os.rename(ruta + file, ruta + '/' + stn + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stns1 = os.listdir(ruta1)\n",
    "stns2 = os.listdir(ruta2)\n",
    "stns = list(set(stns1 + stns2))\n",
    "stns.sort()\n",
    "len(stns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAIH_CHC_diario2(estacion, ruta, agregacion='1d', verbose=True):\n",
    "    \"\"\"Genera las series diarias para las estaciones del SAIH Cantábrico.\n",
    "    \n",
    "    Entradas:\n",
    "    ---------\n",
    "    estacion:   str o int. Nombre de la estación\n",
    "    ruta:       str.\n",
    "    agregacion: str. Resolución temporal a la que agregar los datos: '1d' diaria, '1h' horaria, None datos originales cincominutales\n",
    "    verbose:    boolean.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    \"\"\"\n",
    "\n",
    "    # rutas\n",
    "    rutaSAIH1 = ruta + '/Hasta junio de 2015/'\n",
    "    rutaSAIH2 = ruta + '/Desde julio de 2015/'\n",
    "\n",
    "    signames = ['AIPCINC', 'ACQRIO1', 'AINRIO1', 'AITEMEX']\n",
    "\n",
    "    # PARTE 1\n",
    "    # -------\n",
    "    # encontrar archivos de la estación\n",
    "    folders = os.listdir(rutaSAIH1)\n",
    "    for f, folder in enumerate(folders):\n",
    "        if folder[-4:] == str(estacion):\n",
    "            ruta = rutaSAIH1 + folder + '/'\n",
    "            files = []\n",
    "            for file in os.listdir(ruta):\n",
    "                if file[:4] == folder[:4]:\n",
    "                    files.append(file)\n",
    "\n",
    "            # Importar datos cincominutales\n",
    "            data1 = pd.DataFrame()\n",
    "            for i, file in enumerate(files):\n",
    "                # importar serie original\n",
    "                aux = pd.read_csv(ruta + file, sep=';', encoding='latin-1', decimal=',', low_memory=False)\n",
    "                aux.dropna(axis=0, how='all', inplace=True)\n",
    "                aux.Fecha = [datetime.strptime(date, '%d/%m/%Y %H:%M') for date in aux.Fecha]\n",
    "                aux.set_index('Fecha', drop=True, inplace=True)\n",
    "                # reordenar 'aux' por señales\n",
    "                signals, cols = [], []\n",
    "                for signal in aux['Nombre señal'].unique():\n",
    "                    if signal[-7:] in signames:\n",
    "                        signals.append(signal)\n",
    "                aux2 = pd.DataFrame(columns=cols)\n",
    "                for signal in signals:\n",
    "                    temp = aux.loc[aux['Nombre señal'] == signal, 'Valor']\n",
    "                    cols = list(aux2.columns)\n",
    "                    aux2 = pd.concat((aux2, temp), axis=1)\n",
    "                    aux2.columns = cols + [str(estacion) + 'X' + signal[-7:]]\n",
    "                # concatenar a la serie generada\n",
    "                data1 = pd.concat((data1, aux2), axis=0)\n",
    "\n",
    "            # Agregar datos a diarios\n",
    "            data1_d = data1.groupby(by=[data1.index.year, data1.index.month, data1.index.day]).mean()\n",
    "            data1_d.index = [pd.datetime(y, m, d).date() for (y, m, d) in data1_d.index]\n",
    "\n",
    "            st, en = data1_d.index[0], data1_d.index[-1]\n",
    "            if data1_d.shape[0] != pd.date_range(st, en).shape[0]:\n",
    "                aux = data1_d.copy()\n",
    "                data1_d = pd.DataFrame(index=pd.date_range(st, en), columns=data1_d.columns)\n",
    "                for date in aux.index:\n",
    "                    data1_d.loc[date, :] = aux.loc[date, :]\n",
    "            del files, folders\n",
    "            break\n",
    "\n",
    "    # PARTE 2\n",
    "    # -------\n",
    "    # encontrar carpeta de la estación\n",
    "    folders = os.listdir(rutaSAIH2)\n",
    "    for folder in folders:\n",
    "        if folder[-4:] == str(estacion):\n",
    "            ruta = rutaSAIH2 + folder + '/'\n",
    "            # encontrar archivos de la estación\n",
    "            files = os.listdir(ruta)\n",
    "\n",
    "            # Importar datos cincominutales\n",
    "            data2 = pd.DataFrame()\n",
    "            for file in files:\n",
    "                aux = pd.read_csv(ruta + file, sep=';', decimal=',', encoding='latin-1', skiprows=1)\n",
    "                aux['Fecha/Hora'] = [datetime.strptime(date, '%d/%m/%Y %H:%M') for date in aux['Fecha/Hora']]\n",
    "                aux.set_index('Fecha/Hora', drop=True, inplace=True)\n",
    "                aux.index.name = 'Fecha'\n",
    "                cols = []\n",
    "                for col in aux.columns:\n",
    "                    if col[-7:] in signames:\n",
    "                        cols.append(col)\n",
    "                aux = aux.loc[:, cols]\n",
    "                data2 = pd.concat((data2, aux), axis=0)\n",
    "\n",
    "            # Agregar datos a diarios\n",
    "            data2_d = data2.groupby(by=[data2.index.year, data2.index.month, data2.index.day]).mean()\n",
    "            data2_d.index = [pd.datetime(y, m, d).date() for (y, m, d) in data2_d.index]\n",
    "\n",
    "            st, en = data2_d.index[0], data2_d.index[-1]\n",
    "            if data2_d.shape[0] != pd.date_range(st, en).shape[0]:\n",
    "                aux = data2_d.copy()\n",
    "                data2_d = pd.DataFrame(index=pd.date_range(st, en), columns=data2_d.columns)\n",
    "                for date in aux.index:\n",
    "                    data2_d.loc[date, :] = aux.loc[date, :]\n",
    "            del files, folders\n",
    "            break\n",
    "\n",
    "    # UNIR SERIES\n",
    "    # -----------\n",
    "    # unir las dos series\n",
    "    if ('data1_d' in locals()) and ('data2_d' in locals()):\n",
    "        st1, en1 = data1_d.index[0], data1_d.index[-1]\n",
    "        st2, en2 = data2_d.index[0], data2_d.index[-1]\n",
    "        idx = pd.date_range(st1, en2)\n",
    "        data_d = pd.DataFrame(index=idx, columns=data1_d.columns)\n",
    "        data_d.loc[st2:en2,:] = data2_d\n",
    "        data_d.loc[st1:en1,:] = data1_d\n",
    "    elif ('data1_d' in locals()) and ('data2_d' not in locals()):\n",
    "        data_d = data1_d.copy()\n",
    "    elif ('data2_d' in locals()) and ('data1_d' not in locals()): \n",
    "        data_d = data2_d.copy()\n",
    "\n",
    "    # corregir columnas\n",
    "    cols = []\n",
    "    for col in data_d.columns:\n",
    "        if col[-8:] == 'XACQRIO1':\n",
    "            data_d[col] = [round(d, 1) for d in data_d[col]]\n",
    "            cols.append('caudal_m³/s')\n",
    "        elif col[-8:] == 'XAINRIO1':\n",
    "            data_d[col] = [round(d, 3) for d in data_d[col]]\n",
    "            cols.append('nivel_m')\n",
    "        elif col[-8:] == 'XAIPCINC':\n",
    "            data_d[col] = data_d[col] * 24 * 60 / 5 # precipitación diaria acumulada\n",
    "            data_d[col] = [round(d, 1) for d in data_d[col]]\n",
    "            cols.append('precipitacion_mm')\n",
    "        elif col[-8:] == 'XAITEMEX':\n",
    "            data_d[col] = [round(d, 1) for d in data_d[col]]\n",
    "            cols.append('temperatura_ºC')\n",
    "    data_d.columns = cols\n",
    "    data_d.index.name = 'Fecha'\n",
    "\n",
    "    # comprobar fechas\n",
    "    st, en = data_d.index[0], data_d.index[-1]\n",
    "    if data_d.shape[0] != pd.date_range(st, en).shape[0]:\n",
    "        print('¡ERROR AL UNIR SERIES! Distinto número de filas que días entre la fecha inicial y final.')\n",
    "        return\n",
    "    \n",
    "    # exportar\n",
    "    if not os.path.exists(rutaSAIH + agregacion + '/'):\n",
    "            os.makedirs(rutaSAIH + agregacion + '/')\n",
    "    data_d.to_csv(rutaSAIH + agregacion + '/' + str(estacion) + '.csv', sep=',', na_rep=-100)\n",
    "\n",
    "    if verbose == True:\n",
    "        print('nº de días de las serie:\\t', data_d.shape[0])\n",
    "        print('variables:\\t', list(data_d.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAIH_CHC_diario2('A050', rutaSAIH, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, stn in enumerate(stns):\n",
    "    print('estación', str(stn), '\\tserie', i, 'de', len(stns))\n",
    "    SAIH_CHC_diario2(stn, rutaSAIH, verbose=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAIH_CHC_diario3(estacion, ruta, freq=None, verbose=True):\n",
    "    \"\"\"Genera las series diarias para las estaciones del SAIH Cantábrico.\n",
    "    \n",
    "    Entradas:\n",
    "    ---------\n",
    "    estacion:  str o int. Nombre de la estación\n",
    "    ruta:      str.\n",
    "    freq:      str. Resolución temporal a la que agregar los datos: '1A' anual, '1M' mensual, 1D' diaria, '1H' horaria, 'None' datos originales cincominutales\n",
    "    verbose:   boolean.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    \"\"\"\n",
    "\n",
    "    # rutas\n",
    "    rutaSAIH1 = ruta + '/Hasta junio de 2015/'\n",
    "    rutaSAIH2 = ruta + '/Desde julio de 2015/'\n",
    "\n",
    "    signames = ['AIPCINC', 'ACQRIO1', 'AINRIO1', 'AITEMEX']\n",
    "    \n",
    "    # PARTE 1\n",
    "    # -------\n",
    "    # encontrar archivos de la estación\n",
    "    folders = os.listdir(rutaSAIH1)\n",
    "    for f, folder in enumerate(folders):\n",
    "        if folder[-4:] == str(estacion):\n",
    "            ruta = rutaSAIH1 + folder + '/'\n",
    "            files = []\n",
    "            for file in os.listdir(ruta):\n",
    "                if file[:4] == folder[:4]:\n",
    "                    files.append(file)\n",
    "\n",
    "            # Importar datos cincominutales\n",
    "            data1 = pd.DataFrame()\n",
    "            for i, file in enumerate(files):\n",
    "                # importar serie original\n",
    "                aux = pd.read_csv(ruta + file, sep=';', encoding='latin-1', decimal=',', low_memory=False)\n",
    "                aux.dropna(axis=0, how='all', inplace=True)\n",
    "                aux.Fecha = [datetime.strptime(date, '%d/%m/%Y %H:%M') for date in aux.Fecha]\n",
    "                aux.set_index('Fecha', drop=True, inplace=True)\n",
    "                # reordenar 'aux' por señales\n",
    "                signals, cols = [], []\n",
    "                for signal in aux['Nombre señal'].unique():\n",
    "                    if signal[-7:] in signames:\n",
    "                        signals.append(signal)\n",
    "                aux2 = pd.DataFrame(columns=cols)\n",
    "                for signal in signals:\n",
    "                    temp = aux.loc[aux['Nombre señal'] == signal, 'Valor']\n",
    "                    cols = list(aux2.columns)\n",
    "                    aux2 = pd.concat((aux2, temp), axis=1)\n",
    "                    aux2.columns = cols + [str(estacion) + 'X' + signal[-7:]]\n",
    "                # concatenar a la serie generada\n",
    "                data1 = pd.concat((data1, aux2), axis=0)\n",
    "            del files, folders\n",
    "            break\n",
    "\n",
    "    # PARTE 2\n",
    "    # -------\n",
    "    # encontrar carpeta de la estación\n",
    "    folders = os.listdir(rutaSAIH2)\n",
    "    for folder in folders:\n",
    "        if folder[-4:] == str(estacion):\n",
    "            ruta = rutaSAIH2 + folder + '/'\n",
    "            # encontrar archivos de la estación\n",
    "            files = os.listdir(ruta)\n",
    "\n",
    "            # Importar datos cincominutales\n",
    "            data2 = pd.DataFrame()\n",
    "            for file in files:\n",
    "                aux = pd.read_csv(ruta + file, sep=';', decimal=',', encoding='latin-1', skiprows=1)\n",
    "                aux['Fecha/Hora'] = [datetime.strptime(date, '%d/%m/%Y %H:%M') for date in aux['Fecha/Hora']]\n",
    "                aux.set_index('Fecha/Hora', drop=True, inplace=True)\n",
    "                aux.index.name = 'Fecha'\n",
    "                cols = []\n",
    "                for col in aux.columns:\n",
    "                    if col[-7:] in signames:\n",
    "                        cols.append(col)\n",
    "                aux = aux.loc[:, cols]\n",
    "                data2 = pd.concat((data2, aux), axis=0)\n",
    "            del files, folders   \n",
    "            break\n",
    "\n",
    "    # UNIR SERIES\n",
    "    # -----------\n",
    "    # unir las dos series\n",
    "    if ('data1' in locals()) and ('data2' in locals()):\n",
    "        st1, en1 = data1.index[0], data1.index[-1]\n",
    "        st2, en2 = data2.index[0], data2.index[-1]\n",
    "        idx = pd.date_range(st1, en2)\n",
    "        data = pd.DataFrame(index=idx, columns=data1_d.columns)\n",
    "        data.loc[st2:en2,:] = data2_d\n",
    "        data.loc[st1:en1,:] = data1_d\n",
    "    elif ('data1' in locals()) and ('data2' not in locals()):\n",
    "        data = data1.copy()\n",
    "    elif ('data2' in locals()) and ('data1' not in locals()): \n",
    "        data = data2.copy()\n",
    "    \n",
    "    # Agregar datos\n",
    "    if freq == None:\n",
    "        freq = '5min'\n",
    "        data_ag = data.copy()\n",
    "    elif freq == '1H':\n",
    "        by = [data.index.year, data.index.month, data.index.day, data.index.hour]\n",
    "        data_ag = data.groupby(by=by).mean()\n",
    "        data_ag.index = [pd.datetime(y, m, d, h) for (y, m, d, h) in data_ag.index]\n",
    "    elif freq == '1D':\n",
    "        by = [data.index.year, data.index.month, data.index.day]\n",
    "        data_ag = data.groupby(by=by).mean()\n",
    "        data_ag.index = [pd.datetime(y, m, d).date() for (y, m, d) in data_ag.index]\n",
    "    elif freq == '1M':\n",
    "        by = [data.index.year, data.index.month]\n",
    "        data_ag = data.groupby(by=by).mean()\n",
    "        data_ag.index = [pd.datetime(y, m).date() for (y, m) in data_ag.index]\n",
    "    elif freq == '1A':\n",
    "        by = [data.index.year,]\n",
    "        data_ag = data.groupby(by=by).mean()\n",
    "        data_ag.index = [pd.datetime(y).date() for (y) in data_ag.index]\n",
    "    \n",
    "    st, en = data1_d.index[0], data1_d.index[-1]\n",
    "    if data_ag.shape[0] != pd.date_range(st, en, freq=freq).shape[0]:\n",
    "        aux = data_ag.copy()\n",
    "        data1_ag = pd.DataFrame(index=pd.date_range(st, en, freq=freq), columns=data_ag.columns)\n",
    "        for date in aux.index:\n",
    "            data_ag.loc[date, :] = aux.loc[date, :]\n",
    "\n",
    "    # corregir columnas\n",
    "    cols = []\n",
    "    for col in data_ag.columns:\n",
    "        if col[-8:] == 'XACQRIO1':\n",
    "            data_ag[col] = [round(d, 1) for d in data_ag[col]]\n",
    "            cols.append('caudal_m³/s')\n",
    "        elif col[-8:] == 'XAINRIO1':\n",
    "            data_ag[col] = [round(d, 3) for d in data_ag[col]]\n",
    "            cols.append('nivel_m')\n",
    "        elif col[-8:] == 'XAIPCINC':\n",
    "            data_ag[col] = data_ag[col] * 24 * 60 / 5 # precipitación diaria acumulada\n",
    "            data_ag[col] = [round(d, 1) for d in data_ag[col]]\n",
    "            cols.append('precipitacion_mm')\n",
    "        elif col[-8:] == 'XAITEMEX':\n",
    "            data_ag[col] = [round(d, 1) for d in data_ag[col]]\n",
    "            cols.append('temperatura_ºC')\n",
    "    data_ag.columns = cols\n",
    "    data_ag.index.name = 'Fecha'\n",
    "\n",
    "    # comprobar fechas\n",
    "    st, en = data_ag.index[0], data_ag.index[-1]\n",
    "    if data_ag.shape[0] != pd.date_range(st, en, freq=freq).shape[0]:\n",
    "        print('¡ERROR AL UNIR SERIES! Distinto número de filas que días entre la fecha inicial y final.')\n",
    "        return\n",
    "    \n",
    "    # exportar\n",
    "    if not os.path.exists(ruta + freq + '/'):\n",
    "            os.makedirs(ruta + freq + '/')\n",
    "    data_ag.to_csv(ruta + freq + '/' + str(estacion) + '.csv', sep=',', na_rep=-100)\n",
    "\n",
    "    if verbose == True:\n",
    "        print('nº de días de las serie:\\t', data_ag.shape[0])\n",
    "        print('variables:\\t', list(data_ag.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAIH_CHC_diario3('A047', rutaSAIH, freq=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = pd.read_csv(rutaSAIH1 + 'A047/A047-2007.csv', sep=';', decimal=',', encoding='latin-1', skiprows=0)\n",
    "aux.dropna(axis=0, how='all', inplace=True)\n",
    "aux.Fecha = [datetime.strptime(date, '%d/%m/%Y %H:%M') for date in aux.Fecha]\n",
    "aux.set_index('Fecha', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.index[0], aux.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rango = pd.date_range(aux.index[0], aux.index[-1], freq='A')\n",
    "rango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
