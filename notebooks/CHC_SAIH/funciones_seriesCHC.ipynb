{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Autor:_    __Jesús Casado__ <br> _Revisión:_ __02/07/2020__ <br>\n",
    "\n",
    "\n",
    "__Descripción__:<br>\n",
    "Funciones para extraer, combinar y agregar las series de datos originales del SAIH Cantábrico.\n",
    "\n",
    "__Cosas a corregir__ <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corregir_errores(serie, n):\n",
    "    \"\"\"Convierte en NaN las partes de la serie en las que un mismo valor se repite al menos 'n' veces\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    serie:     series (n,). \n",
    "    n:         número de veces que se permite que se repita un mismo valor\n",
    "    \n",
    "    Salida:\n",
    "    -------\n",
    "    b:         series (m,). Serie corregida\"\"\"\n",
    "    \n",
    "    a = (serie.diff(1) == 0) & (serie != 0)\n",
    "    b = serie.copy()\n",
    "\n",
    "    i = 0\n",
    "    while i < a.shape[0]:\n",
    "        if a.iloc[i]:\n",
    "            c, j = 0, i + 1\n",
    "            while (a.iloc[j]) & (i < a.shape[0]):\n",
    "                print('i = {0:>7}\\tj = {1:>7}\\ttotal = {2:>7}'.format(i, j, a.shape), end='\\r')\n",
    "                c += 1\n",
    "                j += 1\n",
    "            if c >= n:\n",
    "                b.iloc[i:j-1] = np.nan\n",
    "                i = j + 1\n",
    "            else:\n",
    "                i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "            \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corregir_valores(data):\n",
    "    \"\"\"Corrige valores superiores/inferiores a los máximos/mínimos asumibles para cada variable. P.ej. lluvia negativa.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    data:      data frame (n, m). Serie de datos bruta\n",
    "    \n",
    "    Salida:\n",
    "    -------\n",
    "    data:      data frame (n, m). Serie de datos corregida\n",
    "    \"\"\"\n",
    "    \n",
    "    errormin = {'precipitacion_mm': 0, 'caudal_m³/s': 0, 'nivel_m': 0, 'temperatura_C': -10,\n",
    "                'amonio_mg/l': 0, 'conductividad_microS/cm': 0, 'oxigeno_mg/l': 0, 'pH': 0,\n",
    "                'temperaturaAgua_C': -10, 'turbidez_NTU': 0}# 'piezometro_m': 0, 'limnimetro_m': 0, \n",
    "    errormax = {'precipitacion_mm': 100, 'caudal_m³/s': 2000, 'nivel_m': 20, 'temperatura_C': 40,\n",
    "                'amonio_mg/l': 1e4, 'conductividad_microS/cm': 1e6, 'oxigeno_mg/l': 1e3, 'pH': 15,\n",
    "                'temperaturaAgua_C': 50, 'turbidez_NTU': 1e2}# 'piezometro_m': 1e3, 'limnimetro_m': 1e3,\n",
    "    \n",
    "    # corregir valores erróneos\n",
    "    for col in data.columns:\n",
    "        mask = (data[col] < errormin[col]) | (data[col] > errormax[col])\n",
    "        data.loc[mask, col] = np.nan\n",
    "    \n",
    "    # corregir caudal nulo con nivel positivo\n",
    "    if 'caudal_m³/s' in data.columns:\n",
    "        mask = (data['nivel_m'] > 0) & (data['caudal_m³/s'] == 0)\n",
    "        data.loc[mask, 'caudal_m³/s'] = np.nan\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corregir_repes(data, signames):\n",
    "    \"\"\"Encuentra variables (columnas) repetidas en los datos y los unifica en una única serie\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    data:      data frame (n, m). Serie de datos bruta\n",
    "    signames:  dict. Para cada nombre de señal indica el nombre y unidad de la variable medida\n",
    "    \n",
    "    Salida:\n",
    "    -------\n",
    "    data:      data frame (n, o). Serie de datos corregida\n",
    "    \"\"\"\n",
    "    \n",
    "    # variables disponibles\n",
    "    variables = [signames[col[5:]] for col in data.columns]\n",
    "    # encontrar variables repetidas\n",
    "    var = list(set(variables))\n",
    "    varName = [v for v in var if np.sum([v == variable for variable in variables]) > 1]\n",
    "    # posición y nombre de las columnas a corregir\n",
    "    for name in varName:\n",
    "        colPos = [i for i, v in enumerate(variables) if v == name]\n",
    "        colName = data.columns[colPos]\n",
    "        # definir la columna fuente y destino\n",
    "        colDst = data.loc[:, colName].notnull().sum().idxmax()\n",
    "        colSrc = [col for col in colName if col != colDst]\n",
    "        # traspasar datos entre columnas y eliminar columna fuente\n",
    "        if len(colSrc) > 1:\n",
    "            temp = data[colSrc].mean(axis=1)\n",
    "        else:\n",
    "            temp = data[colSrc]\n",
    "        mask = temp.notnull()\n",
    "        data.loc[mask, colDst] = temp.loc[mask]\n",
    "        data.drop(colSrc, axis=1, inplace=True)\n",
    "        del colPos, colName, colSrc, colDst, temp\n",
    "    \n",
    "    return data\n",
    "\n",
    "def corregir_repes(data, signames):\n",
    "    \"\"\"Encuentra variables (columnas) repetidas en los datos y los unifica en una única serie\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    data:      data frame (n, m). Serie de datos bruta\n",
    "    signames:  dict. Para cada nombre de señal indica el nombre y unidad de la variable medida\n",
    "    \n",
    "    Salida:\n",
    "    -------\n",
    "    data:      data frame (n, o). Serie de datos corregida\n",
    "    \"\"\"\n",
    "    \n",
    "    # variables disponibles\n",
    "    variables = [signames[col[5:]] for col in data.columns]\n",
    "    # encontrar variables repetidas\n",
    "    var = list(set(variables))\n",
    "    varName = [v for v in var if np.sum([v == variable for variable in variables]) > 1]\n",
    "    # posición y nombre de las columnas a corregir\n",
    "    for name in varName:\n",
    "        colPos = [i for i, v in enumerate(variables) if v == name]\n",
    "        colName = data.columns[colPos]\n",
    "        # definir la columna destino y fuente\n",
    "        colDst = data.loc[:, colName].notnull().sum().idxmax()\n",
    "        colSrc = [col for col in colName if col != colDst]\n",
    "        # media de las señales\n",
    "        data[colDst] = data[colName].mean(axis=1, skipna=True)\n",
    "        # eliminar señales repetidas\n",
    "        data.drop(colSrc, axis=1, inplace=True)\n",
    "        del colPos, colName, colSrc, colDst\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAIH_CHC(estacion, rutaorig, freq=None, rutaexp=None, verbose=True):\n",
    "    \"\"\"Genera las series diarias para las estaciones del SAIH Cantábrico.\n",
    "    \n",
    "    Entradas:\n",
    "    ---------\n",
    "    estacion:    str o int. Nombre de la estación\n",
    "    ruta:        str.\n",
    "    freq:        str. Resolución temporal a la que remuestrear los datos. Por defecto es 'None', es decir, se genera una serie con la resolución original cincominutal\n",
    "    verbose:     boolean.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    Genera un archivo .csv con la serie de la estación indicada con la resolución temporal indicada (o 5 min si 'freq' es None).\n",
    "    Los archivos se guardan en una subcarpeta dentro de 'ruta' de nombre igual a la frecuencia de la serie.\n",
    "    \"\"\"\n",
    "\n",
    "    # rutas\n",
    "    rutaSAIH1 = rutaorig + '/Hasta junio de 2015/' + str(estacion) + '/'\n",
    "    rutaSAIH2 = rutaorig + '/Desde julio de 2015/' + str(estacion) + '/'\n",
    "\n",
    "    signames = {'AIPCINC': 'precipitacion_mm',\n",
    "                'ACQRIO1': 'caudal_m³/s',\n",
    "                'AINRIO1': 'nivel_m',\n",
    "                'AINRIO2': 'nivel_m',\n",
    "                'AINRL7S': 'nivel_m',\n",
    "                'AITEMEX': 'temperatura_C',\n",
    "                #'_PIEZO': 'piezometro_m',\n",
    "                #'_POZO': 'piezometro_m',\n",
    "                #'_LIMNI': 'limnimetro_m',\n",
    "                'AIA3ATS': 'amonio_mg/l',\n",
    "                'AIMPCTS': 'conductividad_microS/cm',\n",
    "                'AIMPO2S': 'oxigeno_mg/l',\n",
    "                'AIMPPHS': 'pH',\n",
    "                'AIMPTTS': 'temperaturaAgua_C',\n",
    "                'AITUTUS': 'turbidez_NTU'}\n",
    "    redondeo = {'precipitacion_mm': 1, 'caudal_m³/s': 2, 'nivel_m': 2, 'temperatura_C': 1,\n",
    "                'amonio_mg/l': 2, 'conductividad_microS/cm': 0, 'oxigeno_mg/l': 1, 'pH': 1,\n",
    "                'temperaturaAgua_C': 1, 'turbidez_NTU': 0}# 'piezometro_m': 3, 'limnimetro_m': 3, \n",
    "    \n",
    "    # PARTE 1\n",
    "    # -------\n",
    "    if os.path.exists(rutaSAIH1):\n",
    "        # encontrar archivos de la estación\n",
    "        files = [file for file in os.listdir(rutaSAIH1) if file[:4] == str(estacion)]\n",
    "\n",
    "        # Importar datos cincominutales\n",
    "        data1 = pd.DataFrame()\n",
    "        for i, file in enumerate(files):\n",
    "            print('{0:30}'.format(file), end='\\r')\n",
    "            # importar serie original\n",
    "            aux = pd.read_csv(rutaSAIH1 + file, sep=';', encoding='latin-1', decimal=',',\n",
    "                              low_memory=False, na_values=[-100, 65535, 6523.6, -816])\n",
    "            aux.dropna(axis=0, how='all', inplace=True)\n",
    "            aux.Fecha = [datetime.strptime(date, '%d/%m/%Y %H:%M') for date in aux.Fecha]\n",
    "            aux.set_index('Fecha', drop=True, inplace=True)\n",
    "            aux.loc[aux.Calidad == 3, 'Valor'] = np.nan # eliminar datos con baja calidad\n",
    "            aux.loc[aux.Calidad == 5, 'Valor'] = np.nan # eliminar datos con baja calidad\n",
    "            aux.loc[aux.Calidad == -6, 'Valor'] = np.nan # eliminar datos con baja calidad\n",
    "            # reordenar 'aux' por señales\n",
    "            signals = [signal for signal in aux['Nombre señal'].unique() if signal[-7:] in list(signames.keys())]\n",
    "            aux2 = pd.DataFrame(index=pd.date_range(aux.index.min(), aux.index.max(), freq='5min'))#columns=cols)\n",
    "            for signal in signals:\n",
    "                new_col = '{0}X{1}'.format(estacion, signal[-7:])\n",
    "                temp = aux.loc[aux['Nombre señal'] == signal, 'Valor']\n",
    "                aux2.loc[temp.index, new_col] = temp\n",
    "#             aux2 = pd.DataFrame()#columns=cols)\n",
    "#             for signal in signals:\n",
    "#                 new_col = '{0}X{1}'.format(estacion, signal[-7:])\n",
    "#                 temp = aux.loc[aux['Nombre señal'] == signal, 'Valor']\n",
    "#                 try:\n",
    "#                     cols = list(aux2.columns)\n",
    "#                     aux2 = pd.concat((aux2, temp), axis=1, sort=True)\n",
    "#                     aux2.columns = cols + [new_col]\n",
    "#                 except:\n",
    "#                     At = temp.index[1] - temp.index[0]\n",
    "#                     At = int(At.seconds / 60) # minutos\n",
    "#                     if At != 5:\n",
    "#                         temp2 = pd.Series(index=pd.date_range(aux2.index[0], aux2.index[-1], freq='5min'),\n",
    "#                                           dtype='float')\n",
    "#                         temp2[temp.index] = temp\n",
    "#                         aux2[new_col] = temp2\n",
    "            # concatenar a la serie generada\n",
    "            data1 = pd.concat((data1, aux2), axis=0, sort=True)\n",
    "        del files\n",
    "\n",
    "    # PARTE 2\n",
    "    # -------\n",
    "    if os.path.exists(rutaSAIH2):\n",
    "        # encontrar archivos de la estación\n",
    "        files = os.listdir(rutaSAIH2)\n",
    "        # corregir nombre del archivo si fuera necesario\n",
    "        for i, file in enumerate(files):\n",
    "            if len(file) > 16:\n",
    "                new_file = file[:12] + file[-4:]\n",
    "                try:\n",
    "                    os.rename(ruta_stn + file, ruta_stn + new_file)\n",
    "                    files[i] = new_file\n",
    "                except:\n",
    "                    continue\n",
    "        # Importar datos cincominutales\n",
    "        data2 = pd.DataFrame()\n",
    "        for file in files:\n",
    "            print('{0:30}'.format(file), end='\\r')\n",
    "            aux = pd.read_csv(rutaSAIH2 + file, sep=';', decimal=',', encoding='latin-1', skiprows=1)\n",
    "            aux['Fecha/Hora'] = [datetime.strptime(date, '%d/%m/%Y %H:%M') for date in aux['Fecha/Hora']]\n",
    "            aux.set_index('Fecha/Hora', drop=True, inplace=True)\n",
    "            aux.index.name = 'Fecha'\n",
    "            cols = [col for col in aux.columns if col[5:] in list(signames.keys())]\n",
    "            aux = aux.loc[:, cols]\n",
    "            data2 = pd.concat((data2, aux), axis=0, sort=True)\n",
    "        del files\n",
    "    \n",
    "    # UNIR SERIES\n",
    "    # -----------\n",
    "    # unir las dos series como serie minutal para evitar errores\n",
    "    if ('data1' in locals()) and ('data2' in locals()):\n",
    "        data = pd.concat((data1, data2), axis=0, sort=True)\n",
    "    elif ('data1' in locals()) and ('data2' not in locals()):\n",
    "        data = data1\n",
    "    elif ('data2' in locals()) and ('data1' not in locals()): \n",
    "        data = data2\n",
    "\n",
    "    # combinar columnas con la misma variable y cambiar nombre de las columnas\n",
    "    data = corregir_repes(data, signames)\n",
    "    # corregir nombre de las columnas de señales a variables\n",
    "    data.index.name = 'Fecha'\n",
    "    data.columns = [signames[col[5:]] for col in data.columns if col[5:] in list(signames.keys())]\n",
    "    # corregir valores\n",
    "    data = corregir_valores(data)\n",
    "    \n",
    "    # AGREGAR DATOS A LA FRECUENCIA DESEADA\n",
    "    # -------------------------------------\n",
    "    data_ag = data.resample(freq).mean()\n",
    "    if 'precipitacion_mm' in data.columns:\n",
    "        data_ag['precipitacion_mm'] *= data['precipitacion_mm'].resample(freq).count()\n",
    "    data_ag = data_ag.astype(float).round(redondeo)\n",
    "    # recortar serie al primer y último dato útil\n",
    "    st, en = data_ag.first_valid_index(), data_ag.last_valid_index()\n",
    "    data_ag = data_ag.loc[st:en, :]\n",
    "    # ordenar columnas alfabéticamente\n",
    "    data_ag.sort_index(axis=1, inplace=True)\n",
    "        \n",
    "    # EXPORTAR\n",
    "    # --------\n",
    "    # exportar la serie remuestreada\n",
    "    if (freq != None) and (rutaexp != None):\n",
    "        ruta_ag = rutaexp + freq + '/'\n",
    "        if not os.path.exists(ruta_ag):\n",
    "            os.makedirs(ruta_ag)\n",
    "        # generar encabezado\n",
    "        header = ['inicio\\t{0}\\n'.format(data_ag.index[0])]\n",
    "        header.append('At\\t\\t{0}\\n'.format(freq))\n",
    "        header.append('n\\t\\t{0}\\n\\n'.format(data_ag.shape[0]))\n",
    "        # escribir archivo nuevo\n",
    "        with open(ruta_ag + str(estacion) + '.csv', 'w') as f:\n",
    "            for line in header:\n",
    "                f.write(line)\n",
    "            data_ag.to_csv(f, index=False, line_terminator='\\n', sep=',', na_rep='', encoding='latin1')\n",
    "#         data_ag.to_csv(ruta_ag + str(estacion) + '.csv', sep=',', na_rep='', encoding='latin1')#,\n",
    "#                        #float_format='%.3f')\n",
    "\n",
    "    if verbose == True:\n",
    "        print('nº de días de la serie:\\t', data_ag.shape[0])\n",
    "        print('variables:\\t', list(data_ag.columns))\n",
    "        \n",
    "    SAIH_CHC.data = data_ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
