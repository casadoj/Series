{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Autor:_    __Jesús Casado__ <br> _Revisión:_ __02/07/2019__ <br>\n",
    "\n",
    "\n",
    "__Descripción__:<br>\n",
    "Funciones para extraer, combinar y agregar las series de datos originales del SAIH Cantábrico.\n",
    "\n",
    "__Cosas a corregir__ <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAIH_CHC2(estacion, rutaorig, freq=None, export_orig=False, rutaexp=None,\n",
    "                  verbose=True):\n",
    "    \"\"\"Genera las series diarias para las estaciones del SAIH Cantábrico.\n",
    "    \n",
    "    Entradas:\n",
    "    ---------\n",
    "    estacion:    str o int. Nombre de la estación\n",
    "    ruta:        str.\n",
    "    freq:        str. Resolución temporal a la que remuestrear los datos. Por defecto es 'None', es decir, se genera una serie con la resolución original cincominutal\n",
    "    export_orig: boolean. Si exportar o no la serie original cincominutal\n",
    "    verbose:     boolean.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    Genera un archivo .csv con la serie de la estación indicada con la resolución temporal indicada (o 5 min si 'freq' es None). Si 'freq' es distinto de None y 'export_orig' es True, se exporta la serie cincominutal además de la serie de frecuencia indicada.\n",
    "    Los archivos se guardan en una subcarpeta dentro de 'ruta' de nombre igual a la frecuencia de la serie.\n",
    "    \"\"\"\n",
    "\n",
    "    # rutas\n",
    "    rutaSAIH1 = rutaorig + '/Hasta junio de 2015/'\n",
    "    rutaSAIH2 = rutaorig + '/Desde julio de 2015/'\n",
    "\n",
    "    signames = {'AIPCINC': 'precipitacion_mm',\n",
    "                'ACQRIO1': 'caudal_m³/s',\n",
    "                'AINRIO1': 'nivel_m',\n",
    "                'AINRL7S': 'nivel_m',\n",
    "                'AITEMEX': 'temperatura_ºC',\n",
    "                #'_PIEZO': 'piezometro_m',\n",
    "                #'_POZO': 'piezometro_m',\n",
    "                #'_LIMNI': 'limnimetro_m',\n",
    "                'AIA3ATS': 'amonio_mg/l',\n",
    "                'AIMPCTS': 'conductividad_μS/cm',\n",
    "                'AIMPO2S': 'oxigeno_mg/l',\n",
    "                'AIMPPHS': 'pH',\n",
    "                'AIMPTTS': 'temperaturaAgua_ºC',\n",
    "                'AITUTUS': 'turbidez_NTU'}\n",
    "    redondeo = {'precipitacion_mm': 1, 'caudal_m³/s': 2, 'nivel_m': 2, 'temperatura_ºC': 3,\n",
    "                'amonio_mg/l': 2, 'conductividad_μS/cm': 0, 'oxigeno_mg/l': 1, 'pH': 1,\n",
    "                'temperaturaAgua_ºC': 1, 'turbidez_NTU': 0}# 'piezometro_m': 3, 'limnimetro_m': 3, \n",
    "    errormin = {'precipitacion_mm': 0, 'caudal_m³/s': 0, 'nivel_m': 0, 'temperatura_ºC': -50,\n",
    "                'amonio_mg/l': 0, 'conductividad_μS/cm': 0, 'oxigeno_mg/l': 0, 'pH': 0,\n",
    "                'temperaturaAgua_ºC': -10, 'turbidez_NTU': 0}# 'piezometro_m': 0, 'limnimetro_m': 0, \n",
    "    errormax = {'precipitacion_mm': 500, 'caudal_m³/s': 2000, 'nivel_m': 20, 'temperatura_ºC': 50,\n",
    "                'amonio_mg/l': 1e4, 'conductividad_μS/cm': 1e6, 'oxigeno_mg/l': 1e3, 'pH': 15,\n",
    "                'temperaturaAgua_ºC': 50, 'turbidez_NTU': 1e2}# 'piezometro_m': 1e3, 'limnimetro_m': 1e3, \n",
    "    \n",
    "    # PARTE 1\n",
    "    # -------\n",
    "    # encontrar archivos de la estación\n",
    "    folders = os.listdir(rutaSAIH1)\n",
    "    for f, folder in enumerate(folders):\n",
    "        if folder[:4] == str(estacion):\n",
    "            ruta_stn = rutaSAIH1 + folder + '/'\n",
    "            files = [file for file in os.listdir(ruta_stn) if file[:4] == folder[:4]]\n",
    "\n",
    "            # Importar datos cincominutales\n",
    "            data1 = pd.DataFrame()\n",
    "            for i, file in enumerate(files):\n",
    "                # importar serie original\n",
    "                aux = pd.read_csv(ruta_stn + file, sep=';', encoding='latin-1', decimal=',', low_memory=False, na_values=[-100, 65535, 6523.6, -816])\n",
    "                aux.dropna(axis=0, how='all', inplace=True)\n",
    "                aux.Fecha = [datetime.strptime(date, '%d/%m/%Y %H:%M') for date in aux.Fecha]\n",
    "                aux.set_index('Fecha', drop=True, inplace=True)\n",
    "                # reordenar 'aux' por señales\n",
    "                signals = [signal for signal in aux['Nombre señal'].unique() if signal[-7:] in list(signames.keys())]\n",
    "                aux2 = pd.DataFrame()#columns=cols)\n",
    "                for signal in signals:\n",
    "                    temp = aux.loc[aux['Nombre señal'] == signal, 'Valor']\n",
    "                    cols = list(aux2.columns)\n",
    "                    aux2 = pd.concat((aux2, temp), axis=1, sort=True)\n",
    "                    aux2.columns = cols + [str(estacion) + 'X' + signal[-7:]]\n",
    "                # concatenar a la serie generada\n",
    "                data1 = pd.concat((data1, aux2), axis=0, sort=True)\n",
    "            del files, folders\n",
    "            break\n",
    "    \n",
    "    # PARTE 2\n",
    "    # -------\n",
    "    # encontrar carpeta de la estación\n",
    "    folders = os.listdir(rutaSAIH2)\n",
    "    for folder in folders:\n",
    "        if folder[:4] == str(estacion):\n",
    "            ruta_stn = rutaSAIH2 + folder + '/'\n",
    "            # encontrar archivos de la estación\n",
    "            files = os.listdir(ruta_stn)\n",
    "            # corregir nombre del archivo si fuera necesario\n",
    "            for i, file in enumerate(files):\n",
    "                if len(file) > 16:\n",
    "                    new_file = file[:12] + file[-4:]\n",
    "                    try:\n",
    "                        os.rename(ruta_stn + file, ruta_stn + new_file)\n",
    "                        files[i] = new_file\n",
    "                    except:\n",
    "                        continue\n",
    "            # Importar datos cincominutales\n",
    "            data2 = pd.DataFrame()\n",
    "            for file in files:\n",
    "                aux = pd.read_csv(ruta_stn + file, sep=';', decimal=',', encoding='latin-1', skiprows=1)\n",
    "                aux['Fecha/Hora'] = [datetime.strptime(date, '%d/%m/%Y %H:%M') for date in aux['Fecha/Hora']]\n",
    "                aux.set_index('Fecha/Hora', drop=True, inplace=True)\n",
    "                aux.index.name = 'Fecha'\n",
    "                #cols = [col for col in aux.columns if col[-7:] in list(signames.keys())]\n",
    "                cols = [col for col in aux.columns if col[5:] in list(signames.keys())]\n",
    "                aux = aux.loc[:, cols]\n",
    "                data2 = pd.concat((data2, aux), axis=0, sort=True)\n",
    "            del files, folders   \n",
    "            break\n",
    "    \n",
    "    # UNIR SERIES\n",
    "    # -----------\n",
    "    # unir las dos series como serie minutal para evitar errores\n",
    "    if ('data1' in locals()) and ('data2' in locals()):\n",
    "        idx = pd.date_range(data1.index[0], data2.index[-1], freq='min')\n",
    "        cols = list(data1.columns) + list(set(data2.columns) - set(data1.columns))\n",
    "        data = pd.DataFrame(index=idx, columns=cols)\n",
    "        data.loc[data2.index,:] = data2\n",
    "        data.loc[data1.index,:] = data1\n",
    "    elif ('data1' in locals()) and ('data2' not in locals()):\n",
    "        idx = pd.date_range(data1.index[0], data1.index[-1], freq='min')\n",
    "        data = pd.DataFrame(index=idx, columns=data1.columns)\n",
    "        data.loc[data1.index,:] = data1\n",
    "    elif ('data2' in locals()) and ('data1' not in locals()): \n",
    "        idx = pd.date_range(data2.index[0], data2.index[-1], freq='min')\n",
    "        data = pd.DataFrame(index=idx, columns=data2.columns)\n",
    "        data.loc[data2.index,:] = data2.loc[:, data.columns]\n",
    "    \n",
    "    # Agregar datos a la frecuencia de medición: 5 min\n",
    "    data_5min = data.resample('5min').sum()\n",
    "    # corregir nombre de las columnas\n",
    "    data_5min.index.name = 'Fecha'\n",
    "    data_5min.columns = [signames[col[5:]] for col in data_5min.columns if col[5:] in list(signames.keys())]\n",
    "    #data_5min.columns = [signames[col[-7:]] for col in data_5min.columns if col[-7:] in list(signames.keys())]\n",
    "    # corregir valores\n",
    "    for col in data_5min.columns:\n",
    "        mask = (data_5min[col] < errormin[col]) | (data_5min[col] > errormax[col])\n",
    "        data_5min.loc[mask, col] = np.nan\n",
    "    #for col in data_5min.columns:\n",
    "    #    data_5min[col] = data_5min[col].round(redondeo[col])\n",
    "    data_5min = data_5min.astype(float).round(redondeo)\n",
    "    \n",
    "    # remuestrear datos a la frecuencia deseada\n",
    "    aux = data_5min.copy()  # copia de la serie obervada corregida\n",
    "    if freq != None:\n",
    "        data_ag = aux.resample(freq).sum()\n",
    "        counts = aux.resample(freq).count()\n",
    "        for col in data_ag.columns:\n",
    "            if col in ['caudal_m³/s', 'nivel_m', 'temperatura_ºC']:\n",
    "                data_ag[col] /= counts[col]\n",
    "        #for col in data_ag.columns:\n",
    "        #    data_ag[col] = data_ag[col].round(redondeo[col])\n",
    "        data_ag = data_ag.astype(float).round(redondeo)\n",
    "\n",
    "    # EXPORTAR\n",
    "    # --------\n",
    "    # exportar la serie cincominutal \n",
    "    if (export_orig == True) or (freq == None):\n",
    "        ruta_5min = rutaexp + '5min/'\n",
    "        if not os.path.exists(ruta_5min):\n",
    "            os.makedirs(ruta_5min)\n",
    "        data_5min.to_csv(ruta_5min + str(estacion) + '.csv', sep=',', na_rep='')#,\n",
    "                         #float_format='%.3f')\n",
    "    # exportar la serie remuestreada\n",
    "    if freq != None:\n",
    "        ruta_ag = rutaexp + freq + '/'\n",
    "        if not os.path.exists(ruta_ag):\n",
    "            os.makedirs(ruta_ag)\n",
    "        data_ag.to_csv(ruta_ag + str(estacion) + '.csv', sep=',', na_rep='')#,\n",
    "                       #float_format='%.3f')\n",
    "\n",
    "    if verbose == True:\n",
    "        print('nº de días de las serie:\\t', data_ag.shape[0])\n",
    "        print('variables:\\t', list(data_ag.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAIH_CHC2(estacion, rutaorig, freq=None, export_orig=False, rutaexp=None,\n",
    "                  verbose=True):\n",
    "    \"\"\"Genera las series diarias para las estaciones del SAIH Cantábrico.\n",
    "    \n",
    "    Entradas:\n",
    "    ---------\n",
    "    estacion:    str o int. Nombre de la estación\n",
    "    ruta:        str.\n",
    "    freq:        str. Resolución temporal a la que remuestrear los datos. Por defecto es 'None', es decir, se genera una serie con la resolución original cincominutal\n",
    "    export_orig: boolean. Si exportar o no la serie original cincominutal\n",
    "    verbose:     boolean.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    Genera un archivo .csv con la serie de la estación indicada con la resolución temporal indicada (o 5 min si 'freq' es None). Si 'freq' es distinto de None y 'export_orig' es True, se exporta la serie cincominutal además de la serie de frecuencia indicada.\n",
    "    Los archivos se guardan en una subcarpeta dentro de 'ruta' de nombre igual a la frecuencia de la serie.\n",
    "    \"\"\"\n",
    "\n",
    "    # rutas\n",
    "    rutaSAIH1 = rutaorig + '/Hasta junio de 2015/' + str(estacion) + '/'\n",
    "    rutaSAIH2 = rutaorig + '/Desde julio de 2015/' + str(estacion) + '/'\n",
    "\n",
    "    signames = {'AIPCINC': 'precipitacion_mm',\n",
    "                'ACQRIO1': 'caudal_m³/s',\n",
    "                'AINRIO1': 'nivel_m',\n",
    "                'AINRL7S': 'nivel_m',\n",
    "                'AITEMEX': 'temperatura_ºC',\n",
    "                #'_PIEZO': 'piezometro_m',\n",
    "                #'_POZO': 'piezometro_m',\n",
    "                #'_LIMNI': 'limnimetro_m',\n",
    "                'AIA3ATS': 'amonio_mg/l',\n",
    "                'AIMPCTS': 'conductividad_μS/cm',\n",
    "                'AIMPO2S': 'oxigeno_mg/l',\n",
    "                'AIMPPHS': 'pH',\n",
    "                'AIMPTTS': 'temperaturaAgua_ºC',\n",
    "                'AITUTUS': 'turbidez_NTU'}\n",
    "    redondeo = {'precipitacion_mm': 1, 'caudal_m³/s': 2, 'nivel_m': 2, 'temperatura_ºC': 3,\n",
    "                'amonio_mg/l': 2, 'conductividad_μS/cm': 0, 'oxigeno_mg/l': 1, 'pH': 1,\n",
    "                'temperaturaAgua_ºC': 1, 'turbidez_NTU': 0}# 'piezometro_m': 3, 'limnimetro_m': 3, \n",
    "    errormin = {'precipitacion_mm': 0, 'caudal_m³/s': 0, 'nivel_m': 0, 'temperatura_ºC': -10,\n",
    "                'amonio_mg/l': 0, 'conductividad_μS/cm': 0, 'oxigeno_mg/l': 0, 'pH': 0,\n",
    "                'temperaturaAgua_ºC': -10, 'turbidez_NTU': 0}# 'piezometro_m': 0, 'limnimetro_m': 0, \n",
    "    errormax = {'precipitacion_mm': 500, 'caudal_m³/s': 2000, 'nivel_m': 20, 'temperatura_ºC': 50,\n",
    "                'amonio_mg/l': 1e4, 'conductividad_μS/cm': 1e6, 'oxigeno_mg/l': 1e3, 'pH': 15,\n",
    "                'temperaturaAgua_ºC': 50, 'turbidez_NTU': 1e2}# 'piezometro_m': 1e3, 'limnimetro_m': 1e3, \n",
    "    \n",
    "    # PARTE 1\n",
    "    # -------\n",
    "    # encontrar archivos de la estación\n",
    "    files = [file for file in os.listdir(rutaSAIH1) if file[:4] == str(estacion)]\n",
    "\n",
    "    # Importar datos cincominutales\n",
    "    data1 = pd.DataFrame()\n",
    "    for i, file in enumerate(files):\n",
    "        # importar serie original\n",
    "        aux = pd.read_csv(rutaSAIH1 + file, sep=';', encoding='latin-1', decimal=',', low_memory=False, na_values=[-100, 65535, 6523.6, -816])\n",
    "        aux.dropna(axis=0, how='all', inplace=True)\n",
    "        aux.Fecha = [datetime.strptime(date, '%d/%m/%Y %H:%M') for date in aux.Fecha]\n",
    "        aux.set_index('Fecha', drop=True, inplace=True)\n",
    "        aux.loc[aux.Calidad == -6, 'Valor'] = np.nan # eliminar datos con baja calidad\n",
    "        # reordenar 'aux' por señales\n",
    "        signals = [signal for signal in aux['Nombre señal'].unique() if signal[-7:] in list(signames.keys())]\n",
    "        aux2 = pd.DataFrame()#columns=cols)\n",
    "        for signal in signals:\n",
    "            temp = aux.loc[aux['Nombre señal'] == signal, 'Valor']\n",
    "            cols = list(aux2.columns)\n",
    "            aux2 = pd.concat((aux2, temp), axis=1, sort=True)\n",
    "            aux2.columns = cols + [str(estacion) + 'X' + signal[-7:]]\n",
    "        # concatenar a la serie generada\n",
    "        data1 = pd.concat((data1, aux2), axis=0, sort=True)\n",
    "    del files\n",
    "    # corregir valores erróneos\n",
    "    for col in data1.columns:\n",
    "        mask = (data1[col] < errormin[signames[col[5:]]]) | (data1[col] > errormax[signames[col[5:]]])\n",
    "        data1.loc[mask, col] = np.nan\n",
    "    \n",
    "    # PARTE 2\n",
    "    # -------\n",
    "    # encontrar archivos de la estación\n",
    "    files = os.listdir(rutaSAIH2)\n",
    "    # corregir nombre del archivo si fuera necesario\n",
    "    for i, file in enumerate(files):\n",
    "        if len(file) > 16:\n",
    "            new_file = file[:12] + file[-4:]\n",
    "            try:\n",
    "                os.rename(ruta_stn + file, ruta_stn + new_file)\n",
    "                files[i] = new_file\n",
    "            except:\n",
    "                continue\n",
    "    # Importar datos cincominutales\n",
    "    data2 = pd.DataFrame()\n",
    "    for file in files:\n",
    "        aux = pd.read_csv(rutaSAIH2 + file, sep=';', decimal=',', encoding='latin-1', skiprows=1)\n",
    "        aux['Fecha/Hora'] = [datetime.strptime(date, '%d/%m/%Y %H:%M') for date in aux['Fecha/Hora']]\n",
    "        aux.set_index('Fecha/Hora', drop=True, inplace=True)\n",
    "        aux.index.name = 'Fecha'\n",
    "        #cols = [col for col in aux.columns if col[-7:] in list(signames.keys())]\n",
    "        cols = [col for col in aux.columns if col[5:] in list(signames.keys())]\n",
    "        aux = aux.loc[:, cols]\n",
    "        data2 = pd.concat((data2, aux), axis=0, sort=True)\n",
    "    del files\n",
    "    # corregir valores erróneos\n",
    "    for col in data2.columns:\n",
    "        mask = (data2[col] < errormin[signames[col[5:]]]) | (data2[col] > errormax[signames[col[5:]]])\n",
    "        data2.loc[mask, col] = np.nan\n",
    "    \n",
    "    # UNIR SERIES\n",
    "    # -----------\n",
    "    # unir las dos series como serie minutal para evitar errores\n",
    "    if ('data1' in locals()) and ('data2' in locals()):\n",
    "        data = pd.concat((data1, data2), axis=0, sort=True)\n",
    "    elif ('data1' in locals()) and ('data2' not in locals()):\n",
    "        data = data1\n",
    "    elif ('data2' in locals()) and ('data1' not in locals()): \n",
    "        data = data2\n",
    "    \n",
    "    # combinar columnas con la misma variable\n",
    "    # variables disponibles\n",
    "    variables = [signames[col[5:]] for col in data.columns]\n",
    "    # encontrar variables repetidas\n",
    "    var = list(set(variables))\n",
    "    varName = [v for v in var if np.sum([v == variable for variable in variables]) > 1]\n",
    "    # posición y nombre de las columnas a corregir\n",
    "    for name in varName:\n",
    "        colPos = [i for i, v in enumerate(variables) if v == name]\n",
    "        colName = data.columns[colPos]\n",
    "        # definir la columna fuente y destino\n",
    "        colSrc = data.loc[:, colName].notnull().sum().idxmin()\n",
    "        colDst = data.loc[:, colName].notnull().sum().idxmax()\n",
    "        # traspasar datos entre columnas y eliminar columna fuente\n",
    "        mask = data[colSrc].notnull()\n",
    "        data.loc[mask, colDst] = data.loc[mask, colSrc]\n",
    "        data.drop(colSrc, axis=1, inplace=True)\n",
    "        del colPos, colName, colSrc, colDst\n",
    "        \n",
    "    # corregir nombre de las columnas\n",
    "    data.index.name = 'Fecha'\n",
    "    data.columns = [signames[col[5:]] for col in data.columns if col[5:] in list(signames.keys())]\n",
    "    \n",
    "    # corregir valores\n",
    "    for col in data.columns:\n",
    "        mask = (data[col] < errormin[col]) | (data[col] > errormax[col])\n",
    "        data.loc[mask, col] = np.nan\n",
    "    if 'caudal_m³/s' in data.columns:\n",
    "        mask = (data['nivel_m'] > 0) & (data['caudal_m³/s'] == 0)\n",
    "        data.loc[mask, 'caudal_m³/s'] = np.nan\n",
    "    \n",
    "    # AGREGAR DATOS A LA FRECUENCIA DESEADA\n",
    "    # -------------------------------------\n",
    "    data_ag = data.resample(freq).mean()\n",
    "    if 'precipitacion_mm' in data.columns:\n",
    "        data_ag['precipitacion_mm'] *= data['precipitacion_mm'].resample(freq).count()\n",
    "    data_ag = data_ag.astype(float).round(redondeo)\n",
    "    \n",
    "#     # remuestrear datos a la frecuencia deseada\n",
    "#     aux = data_5min.copy()  # copia de la serie obervada corregida\n",
    "#     if freq != None:\n",
    "#         data_ag = aux.resample(freq).sum()\n",
    "#         counts = aux.resample(freq).count()\n",
    "#         for col in data_ag.columns:\n",
    "#             if col in ['caudal_m³/s', 'nivel_m', 'temperatura_ºC']:\n",
    "#                 data_ag[col] /= counts[col]\n",
    "#         #for col in data_ag.columns:\n",
    "#         #    data_ag[col] = data_ag[col].round(redondeo[col])\n",
    "#         data_ag = data_ag.astype(float).round(redondeo)\n",
    "\n",
    "    # EXPORTAR\n",
    "    # --------\n",
    "#     # exportar la serie cincominutal \n",
    "#     if (export_orig == True) or (freq == None):\n",
    "#         ruta_5min = rutaexp + '5min/'\n",
    "#         if not os.path.exists(ruta_5min):\n",
    "#             os.makedirs(ruta_5min)\n",
    "#         data_5min.to_csv(ruta_5min + str(estacion) + '.csv', sep=',', na_rep='')#,\n",
    "#                          #float_format='%.3f')\n",
    "    # exportar la serie remuestreada\n",
    "    if (freq != None) and (rutaexp != None):\n",
    "        ruta_ag = rutaexp + freq + '/'\n",
    "        if not os.path.exists(ruta_ag):\n",
    "            os.makedirs(ruta_ag)\n",
    "        data_ag.to_csv(ruta_ag + str(estacion) + '.csv', sep=',', na_rep='', encoding='latin1')#,\n",
    "                       #float_format='%.3f')\n",
    "\n",
    "    if verbose == True:\n",
    "        print('nº de días de las serie:\\t', data_ag.shape[0])\n",
    "        print('variables:\\t', list(data_ag.columns))\n",
    "        \n",
    "    SAIH_CHC2.data = data_ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
